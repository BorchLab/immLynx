% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenizeSequences.R
\name{tokenizeSequences}
\alias{tokenizeSequences}
\title{Tokenize Amino Acid Sequences}
\usage{
tokenizeSequences(
  tokenizer,
  aa_sequences,
  padding = TRUE,
  truncation = TRUE,
  return_tensors = "pt"
)
}
\arguments{
\item{tokenizer}{The tokenizer object returned by `initialize_protein_model_and_tokenizer`.}

\item{aa_sequences}{A character vector of amino acid sequences.}

\item{padding}{A logical or string. If TRUE, pads sequences to the length
of the longest sequence in the batch. Defaults to TRUE.}

\item{truncation}{A logical. If TRUE, truncates sequences to the model's
maximum input length. Defaults to TRUE.}

\item{return_tensors}{A string specifying the format for the returned tensors.
"pt" for PyTorch tensors, "tf" for TensorFlow. Defaults to "pt".}
}
\value{
The tokenized output, typically a dictionary-like object containing
  'input_ids' and 'attention_mask'.
}
\description{
Takes a vector of amino acid sequences and uses a Hugging Face
  tokenizer to convert them into numerical input IDs.
}
\examples{
\dontrun{
  hf_components <- initialize_protein_model_and_tokenizer()
  sequences <- c("MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEKAVQVKVKALP",
                 "MKKLFWRAVFLFLLAGLVACSP")
  tokenized_output <- tokenizeSequences(hf_components$tokenizer, sequences)
  print(tokenized_output)
}
}
